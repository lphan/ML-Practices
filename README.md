# ML-Practices (beta)

## INTRO: Few things that I want to tell you

as a person who are very passionate about Data Science, Machine Learning and Deep Learning so that I want to develop a framework layer in between many popular frameworks (Pandas, Numpy, Matplotlib, statsmodels, Tensorflow, Spark, etc.). 
In a short description, package 'Starts' is 'Wrapper' package with the functions which are written with simple algorithms and easy to run and apply as well as exploit the power of many other data analysis frameworks. 
 
I have two goals with this work and I hope it will work in one day:
- for the person who are like me and want to study Machine Learning 'Learn by Doing' are able to get into Machine Learning's technique lightly with less effort and overcome the raw-theories's barrier.
- for the person who want to analyse data and get the result/ information asap, but do not have much time to deal with the complexity of many different frameworks. 

"
By taking a look on the real examples and see how data are being analysed, 
install the frameworks you need and do the similar ways like one of the examples,
improve your result by transforming your ideas into the new functions you like. 
You can always extend/ change/ update this package 'Starts'. 
"

- Finally, it's Open Source on Open Data. In a Github's way, just 'fork, do what you like and pull request'

Loop_of_the_path_to_DataScience_and_MachineLearning:

	1. Study/ review the theories in Machine Learning from different Sources

	2. Implement/ improve the algorithm using Python3 and its frameworks 

	3. Analyzes the data from public sources (scikit-learn, UCI, Kaggle)

	4. Integrate the implementation into the package Starts


## Status of the analysed data packages: On-going updated

> 1_USGS: analyse Pesticide Use in Agriculture. Which compounds are used most frequently in the United States?

> 2_Titanic: predict survival on the Titanic and get familiar with ML basics

> 3_NOAA: analyse El Nino Dataset, Meteorological readings taken from a series of buoys in the equatorial Pacific

> 4_USGS: analyse the significant earthquakes, 1965-2016

> 5_SNAP: implement the interpretation of the 685nm peak in water-leaving radiance spectra in terms of fluorescence, absorption and scattering, and its observation by MERIS (J. F. R. Gower , R. Doerffer & G. A. Borstad), based on framework snappy

> 6_ITA: analyse the Earthquakes that hit Italy between August and November 2016

> 7_AIR: analyse Air Quality Data Set

> 8_ARO: analyse data given by CodeFights and Arundo

> 9_RECS: analyse data of restaurant and consumer and build a recommendation system

> 10_EY: analyse data about marriages and family in Germany from 1950 to 2015 and predict result in 2016 and 2017

> 11_MED: analyse digital data of long physical phenomenon

> 12_WHR: analyse the World Happiness Report, Happiness scored according to economic production, social support

> 13_FEMA: analyse data FEMA Federal Emergency management Agency about federal-disasters and firefighter-fatalities 

> 14_NSIDC: analyse data daily-sea-ice-extent NSIDC National Snow & Ice Data Center


### How-To: run the script .ipynb with jupyter notebook
data need to be downloaded from the reference link in x_foldername 

copy and overwrite the file config.ini and modify the data path accordingly.

jupyter notebook x_foldername/x_filename.ipynb

More information: please check out package Starts


### Data Sources:
> https://www.kaggle.com/

> https://archive.ics.uci.edu/ml/index.php

> http://scikit-learn.org/stable/datasets/index.html
